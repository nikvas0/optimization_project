{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = 1000, 1000 # размерность экспериментов\n",
    "\n",
    "exps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Введение**\n",
    "В экспериментах f и h -- кв. формы, а G -- билинейная форма.\n",
    "\n",
    "Седловая задача имеет вид $F(x) = \\min_x \\left( f(x) + \\max_y \\left( G(x, y) - h(y) \\right) \\right)$\n",
    "\n",
    "$g(x) = \\max_y \\left( G(x, y) - h(y) \\right)$\n",
    "\n",
    "Для генерации кв. форм с заданными $L$ и $\\mu$ используется генерация случайных собственных значений $\\lambda_1, \\ldots, \\lambda_n$ из отрезка $[\\mu, L]$ и умножения $A^T \\cdot diag(\\lambda_1, \\ldots, \\lambda_n) \\cdot A$, где $A$ --- случайная ортонормированная матрица.\n",
    "\n",
    "G --- билинейная форма ($G(x,y) = \\langle x, Ay\\rangle$, где для матрицы $A$ значения выбраны из распределения $U(-1, 1)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_f': 4.000000000000015,\n",
       " 'L_G': 36.348569774988604,\n",
       " 'L_h': 6.00000000000005,\n",
       " 'mu_x': 1.999999999999981,\n",
       " 'mu_y': 2.9999999999999902}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp0, _, _, _ = experiment.generateQuadraticFormExperiment(\n",
    "        N, M,\n",
    "        {'L': 4, 'mu': 2},\n",
    "        {'min': -1, 'max': 1},\n",
    "        {'L': 6, 'mu': 3},\n",
    "        1111\n",
    "    )\n",
    "exps.append(exp0)\n",
    "exp0.constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_f': 8.000000000000034,\n",
       " 'L_G': 36.348569774988604,\n",
       " 'L_h': 12.000000000000103,\n",
       " 'mu_x': 4.000000000000006,\n",
       " 'mu_y': 5.9999999999999885}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp1, _, _, _ = experiment.generateQuadraticFormExperiment(\n",
    "        N, M,\n",
    "        {'L': 8, 'mu': 4},\n",
    "        {'min': -1, 'max': 1},\n",
    "        {'L': 12, 'mu': 6},\n",
    "        1111\n",
    "    )\n",
    "exps.append(exp1)\n",
    "exp1.constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_f': 19.999999999999975,\n",
       " 'L_G': 36.348569774988604,\n",
       " 'L_h': 10.000000000000071,\n",
       " 'mu_x': 2.000000000000004,\n",
       " 'mu_y': 9.000000000000112}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2, _, _, _ = experiment.generateQuadraticFormExperiment(\n",
    "        N, M,\n",
    "        {'L': 20, 'mu': 2},\n",
    "        {'min': -1, 'max': 1},\n",
    "        {'L': 10, 'mu': 9},\n",
    "        1111\n",
    "    )\n",
    "exps.append(exp2)\n",
    "exp2.constants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L_f': 9.999999999999972,\n",
       " 'L_G': 36.348569774988604,\n",
       " 'L_h': 19.999999999999932,\n",
       " 'mu_x': 9.000000000000087,\n",
       " 'mu_y': 2.000000000000015}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp3, _, _, _ = experiment.generateQuadraticFormExperiment(\n",
    "        N, M,\n",
    "        {'L': 10, 'mu': 9},\n",
    "        {'min': -1, 'max': 1},\n",
    "        {'L': 20, 'mu': 2},\n",
    "        1111\n",
    "    )\n",
    "exps.append(exp3)\n",
    "exp3.constants()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "x_0 = np.random.random(N)\n",
    "y_0 = np.random.random(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330.67905945640393, 311.9972004784303)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x_0**2),np.sum(y_0**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение седловой задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение седловой задачи.\n",
    "out --- алгоритм по $x$, in --- алгоритм по $y$.\n",
    "\n",
    "Во внутренней задаче (поиск $y$ для нахождения градиента $g(x)$) для начального значения используется $y$ с предыдущей задачи. Она также решается при помощи ускоренного метаалгоритма.\n",
    "\n",
    "В качестве внутреннего алгоритма используется покомпонентный метод Нестерова.\n",
    "\n",
    "В x_grad_stop_eps и y_grad_stop_eps есть возможность задать остановку по норме градиента вместо числа шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddle(x_0, y_0, exp, k_out=50, k_in=50, k_n=5, x_grad_stop_eps=None, y_grad_stop_eps=None):\n",
    "    c = exp.constants()\n",
    "    \n",
    "    stop_callback_for_y = None\n",
    "    if y_grad_stop_eps is not None:\n",
    "        stop_callback_for_y = lambda grad: np.sum(grad**2) < y_grad_stop_eps**2\n",
    "        \n",
    "    stop_callback_for_x = None\n",
    "    if x_grad_stop_eps is not None:\n",
    "        stop_callback_for_x = lambda grad: np.sum(grad**2) < x_grad_stop_eps**2\n",
    "    \n",
    "    x, y, stats = experiment.runSaddleExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'out': {\n",
    "            'H': c['L_f'] * 5,\n",
    "            'K': k_out,\n",
    "            'stop_callback': stop_callback_for_x\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(c['L_h'] + 2 * (c['L_G']**2) / c['mu_y'])] * N),\n",
    "            'S': np.array([((c['L_h'] + 2 * (c['L_G']**2) / c['mu_y']) + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': c['L_h'] * 5,\n",
    "            'K': k_in,\n",
    "            'stop_callback': stop_callback_for_y\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([c['L_G']] * M),\n",
    "            'S': np.array([(c['L_G'] + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение седловой задачи с увеличивающейся точностью решения по $y$.**\n",
    "\n",
    "out --- алгоритм по $x$, in --- алгоритм по $y$.\n",
    "\n",
    "Идея заключается в том, что на первых итерациях не тратить много шагов на нахождение точного $y$ (решение внутренней задачи),\n",
    "но при этом постепенно увеличивать точность, чтобы в конце решать задачу для $y$ достаточно точно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddleAdaptiveEps(x_0, y_0, exp, k_out=50, k_in=50, k_n=5, eps_start=10**-4, eps_alpha=0.9998):\n",
    "    c = exp.constants()\n",
    "\n",
    "    class CallbackForY:\n",
    "        def __init__(self, eps_start_, eps_alpha_):\n",
    "            self.eps = eps_start_\n",
    "            self.alpha = eps_alpha\n",
    "            \n",
    "        def __call__(self, grad):\n",
    "            self.eps *= self.alpha\n",
    "            return np.sum(grad**2) < self.eps**2\n",
    "    \n",
    "    x, y, stats = experiment.runSaddleExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'out': {\n",
    "            'H': c['L_f'] * 5,\n",
    "            'K': k_out,\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(c['L_h'] + 2 * (c['L_G']**2) / c['mu_y'])] * N),\n",
    "            'S': np.array([((c['L_h'] + 2 * (c['L_G']**2) / c['mu_y']) + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': c['L_h'] * 5,\n",
    "            'K': k_in,\n",
    "            'stop_callback': CallbackForY(eps_start, eps_alpha)\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([c['L_G']] * M),\n",
    "            'S': np.array([(c['L_G'] + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Каталист**\n",
    "\n",
    "Обычное решение дополнительно обернуто в еще один УМ с $f = 0$ и $g = F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddleCatalist(x_0, y_0, exp, k_catalist, mu_mult, k_out=50, k_in=50, k_n=5, x_grad_stop_eps=None, y_grad_stop_eps=None):\n",
    "    c = exp.constants()\n",
    "    \n",
    "    stop_callback_for_y = None\n",
    "    if y_grad_stop_eps is not None:\n",
    "        stop_callback_for_y = lambda grad: np.sum(grad**2) < y_grad_stop_eps**2\n",
    "        \n",
    "    stop_callback_for_x = None\n",
    "    if x_grad_stop_eps is not None:\n",
    "        stop_callback_for_x = lambda grad: np.sum(grad**2) < x_grad_stop_eps**2\n",
    "\n",
    "    x, y, stats = experiment.runSaddleCatalistExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'catalist': {\n",
    "            'H': c['mu_x'] * mu_mult,\n",
    "            'K': k_catalist,\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'out': {\n",
    "            'H': c['L_f'] * 5,\n",
    "            'K': k_out,\n",
    "            'stop_callback': stop_callback_for_x\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(c['L_h'] + 2 * (c['L_G']**2) / c['mu_y'])] * N),\n",
    "            'S': np.array([((c['L_h'] + 2 * (c['L_G']**2) / c['mu_y']) + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': c['L_h'] * 5,\n",
    "            'K': k_in,\n",
    "            'stop_callback': stop_callback_for_y\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([c['L_G']] * M),\n",
    "            'S': np.array([(c['L_G'] + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_res = lambda exp, x, y: exp.f.func(x) + exp.G.func(x, y) - exp.h.func(y)\n",
    "calc_grad_x = lambda exp, x, y: np.sqrt(np.sum((exp.f.grad(x) + exp.G.grad_x(x, y))**2))\n",
    "calc_grad_y = lambda exp, x, y: np.sqrt(np.sum((exp.G.grad_y(x, y) - exp.h.grad(y))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_simple_40 = []\n",
    "res_simple_10 = []\n",
    "#res_simple_5 = []\n",
    "res_simple_eps = []\n",
    "res_catalist_20 = []\n",
    "res_catalist_10 = []\n",
    "res_catalist_eps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперимент 0. params={'L_f': 4.000000000000015, 'L_G': 36.348569774988604, 'L_h': 6.00000000000005, 'mu_x': 1.999999999999981, 'mu_y': 2.9999999999999902}\n"
     ]
    }
   ],
   "source": [
    "res_simple_40 = []\n",
    "res_simple_10 = []\n",
    "#res_simple_5 = []\n",
    "res_catalist_20 = []\n",
    "res_catalist_10 = []\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Эксперимент {}. params={}'.format(i, exp.constants()))\n",
    "    \n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 100, 40, 5)\n",
    "    print('Simple (100, 40): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_40.append(stat)\n",
    "    \n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 400, 10, 5)\n",
    "    print('Simple (400, 10): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_10.append(stat)\n",
    "    \n",
    "    #%time x, y, stat = RunSaddle(x_0, y_0, exp, 600, 7, 5)\n",
    "    #print('Simple (800, 5): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    #res_simple_5.append(stat)\n",
    "    \n",
    "    %time x, y, stat = RunSaddleCatalist(x_0, y_0, exp, 20, 5, 20, 10, 5)\n",
    "    print('Catalist (20, 20, 10): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_catalist_20.append(stat)\n",
    "    \n",
    "    %time x, y, stat = RunSaddleCatalist(x_0, y_0, exp, 40, 5, 10, 10, 5)\n",
    "    print('Catalist (40, 10, 10): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_catalist_10.append(stat)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_simple_eps = []\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Experiment {}. params={}'.format(i, exp.constants()))\n",
    "    \n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 400, 20, 5, None, 1e-4)\n",
    "    print('Simple EPS=1e-4: f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_eps.append(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_simple_adaptive_eps = []\n",
    "res_simple_adaptive_eps_fast = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Эксперимент {}. params={}'.format(i, exp.constants()))\n",
    "    \n",
    "    %time x, y, stat = RunSaddleAdaptiveEps(x_0, y_0, exp, 400, 20, 5, 1e-2, 0.9995)\n",
    "    print('Simple Adaptive EPS=1e-2 alpha=0.9995: f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_adaptive_eps.append(stat)\n",
    "    \n",
    "    #%time x, y, stat = RunSaddleAdaptiveEps(x_0, y_0, exp, 400, 20, 5, 1e-3, 0.9995)\n",
    "    #print('Simple Adaptive EPS=1e-3 alpha=0.9999: f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    #res_simple_adaptive_eps_fast.append(stat)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_catalist_eps = []\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Эксперимент {}. params={}'.format(i, exp.constants()))\n",
    "    \n",
    "    %time x, y, stat = RunSaddleCatalist(x_0, y_0, exp, 20, 5, 20, 20, 5, 1e-4, 1e-4)\n",
    "    print('Catalist EPS=1e-4: f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_catalist_eps.append(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зависимость найденного значения от кол-ва вызовов оракулов $\\nabla f$ и $\\nabla h$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectFfromfOracleSimple(stats):\n",
    "    return stats['out_stats']['fs']\n",
    "\n",
    "def collectFfromhOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r += st['fs']\n",
    "    return r\n",
    "\n",
    "def collectGradNormfromfOracleSimple(stats):\n",
    "    return stats['out_stats']['gs']\n",
    "\n",
    "def collectGradNormfromhOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r += st['gs']\n",
    "    return r\n",
    "\n",
    "def collectFfromfOracleCatalist(stats):\n",
    "    r = []\n",
    "    for st in stats['saddle']:\n",
    "        r += collectFfromfOracleSimple(st)\n",
    "    return r\n",
    "\n",
    "def collectFfromhOracleCatalist(stats):\n",
    "    r = []\n",
    "    for st in stats['saddle']:\n",
    "        r += collectFfromhOracleSimple(st)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(4, 2, 1 + i * 2)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_10[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_10')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_eps')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_adaptive_eps[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_adaptive_eps')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_40')\n",
    "       \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(4, 2, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    Fh = collectFfromhOracleSimple(res_simple_10[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_10')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_eps')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_adaptive_eps[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_adaptive_eps')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_40')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(4, 2, 1 + i * 2 + 0)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_10[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_10')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_eps')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_40')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_adaptive_eps[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_adaptive_eps')\n",
    "    \n",
    "    #Fh = collectFfromhOracleSimple(res_simple_adaptive_eps_fast[i])\n",
    "    #ax.plot(range(len(Fh)), Fh, label='simple_adaptive_eps_fast')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('$||\\\\nabla F_x||$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(4, 2, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_10[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_10')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_eps')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_40')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_adaptive_eps[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_adaptive_eps')\n",
    "    \n",
    "    #Fh = collectFfromhOracleSimple(res_simple_adaptive_eps_fast[i])\n",
    "    #ax.plot(range(len(Fh)), Fh, label='simple_adaptive_eps_fast')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('$||\\\\nabla F_y||$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # TODO: нарисовать получше вторые графики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "simple_* имеют фиксированное число итераций для обоих метаалгоритмов, число означает кол-во итераций поиска по $y$ для одной итерации поиска по $x$.\n",
    "simple_eps имеет проверку на норму градиента для остановки.\n",
    "simple_adaptive_eps --- решают внутреннюю задачу с увеличивающейся точностью.\n",
    "\n",
    "В данном случае корректно сравнивать значение функции, поскольку, как можно видеть, $||\\nabla F_y||$ мал, что означает близость $y$ к оптимуму максимизирующей задачи.\n",
    "\n",
    "Видно, что первые два эксперимента довольно похожи, хотя $L$ и $\\mu$ в них отличаются в 2 раза. Это подтверждает то, что скорость сходимоти зависит от частного величин, а не от них самих. Хотя метод, делающий больше итераций для $x$, сходится быстрее. Это потому, что в данном примере поиск максимума по $y$ для нахождения градиента $g$ запоминает прошлый найденный $y$ и использует его в следующем вызове в качестве стартового значения. Из-за этого внутренний метаалгоритм сходится быстрее, а следовательно увеличение кол-ва итераций в нем будет давать меньший эффект, чем увеличение кол-ва итераций внешнего алгоритма.\n",
    "\n",
    "Из экспериментов 2 и 3 для simple_10 и simple_40 видно, что лучше сходится алгоритм, который делает большее число итераций по тем компонентам (из $x$ и $y$), где число обусловленности $\\frac{L}{\\mu}$ больше. Это полностью согласуется с теоретическими выводами в статье https://arxiv.org/pdf/2004.08691.pdf (для сходимости для $f$ требуется $O(\\sqrt{\\frac{L_f}{\\mu_x}})$ шагов, а для $h$ -- $O(\\sqrt{\\frac{L_h}{\\mu_y}})$ шагов)\n",
    "\n",
    "Можно заметить, что график метода с остановкой по $\\varepsilon$ во всех случаях лучший или очень близок к лучшему методу по сходимости по вызовам $\\nabla f$, однако он не лучший сходимости по вызовам $\\nabla h$. Это потому, что вначале происходят большие шаги по $x$, соответственно по $y$ для нахождения хорошего приближения требуется сделать больше шагов.\n",
    "\n",
    "Для алгоритма с адаптивной точностью видно, что он по вызовам $\\nabla f$ сходится примерно так же, как и алгоритм с обычной остановкой по $\\varepsilon$, однако, если смотреть на сходимоть по $\\nabla h$, видно, что в первых трех экспериментах алгоритм делает меньше вызовов оракула $\\nabla h$. Как видно из гистограмм ниже это происходит из-за того, что много вычислений максимума по $y$ используют меньше итераций. Особенно хорошо это видно на эксперименте $3$.\n",
    "\n",
    "Можно также увидеть, что алгоритм с увеличивающейся точностью сначала получает меньшие значения $f$, однако из этого нельзя делать вывод, что он быстрее сходится, поскольку сначала точность решения max подзадачи низкая, т.е. y может быть недостаточно близок в максимуму. В то же время на графиках нормы оракула видно, что скорость сходимости у увеличивающейся точности примерна такая же.\n",
    "\n",
    "На графиках по $\\nabla h$ есть вертикальные линии (на самом деле они не вертикальные, а так кажется из-за того, что они занимают мало итераций, при том, что на графике итераций десятки тысяч), которые возникают из-за того, что после сдвига по $x$ надо перерешивать задачу по $y$, поскольку он теперь не максимизирует функцию. Чем больше сдвиг по $x$ влияет на функцию, тем больше эти линии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectItersBygOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r.append(st['iters'])\n",
    "    return r\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(20,10))\n",
    "f.suptitle('Распределение кол-ва итераций для поиска $y$\\nдля алгоритма с остановкой по норме градиента', fontsize=16)\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(2, 2, 1 + i)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    ItersByg = collectItersBygOracleSimple(res_simple_eps[i])\n",
    "    \n",
    "    #ax.plot(range(len(ItersByg)), ItersByg)\n",
    "    ax.hist(ItersByg)\n",
    "    \n",
    "    plt.ylabel('вызов оракула $\\\\nabla g$')\n",
    "    plt.xlabel('кол-во итераций для поиска $y$')\n",
    "    plt.grid(True)\n",
    "    #plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectItersBygOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r.append(st['iters'])\n",
    "    return r\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=(20,10))\n",
    "f.suptitle('Распределение кол-ва итераций для поиска $y$\\nдля алгоритма с увеличивающейся точностью', fontsize=16)\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(2, 2, 1 + i)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    ItersByg = collectItersBygOracleSimple(res_simple_adaptive_eps[i])\n",
    "    \n",
    "    #ax.plot(range(len(ItersByg)), ItersByg)\n",
    "    ax.hist(ItersByg)\n",
    "    \n",
    "    plt.ylabel('вызов оракула $\\\\nabla g$')\n",
    "    plt.xlabel('кол-во итераций для поиска $y$')\n",
    "    plt.grid(True)\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "Как видно при использовании остановки по $\\varepsilon$ часто делается мало итераций, однако в большинстве случаев делаются все доступные итерации, т.е. заметного выигрыша по количеству итераций по сравнению с другими методами не получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(4, 2, 1 + i * 2)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    Ff = collectFfromfOracleCatalist(res_catalist_20[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='catalist_20')\n",
    "    \n",
    "    Ff = collectFfromfOracleCatalist(res_catalist_10[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='catalist_10')\n",
    "    \n",
    "    Ff = collectFfromfOracleCatalist(res_catalist_eps[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='catalist_eps')\n",
    "        \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(4, 2, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    Fh = collectFfromhOracleCatalist(res_catalist_20[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='catalist_20')\n",
    "    \n",
    "    Fh = collectFfromhOracleCatalist(res_catalist_10[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='catalist_10')\n",
    "    \n",
    "    Fh = collectFfromhOracleCatalist(res_catalist_eps[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='catalist_eps')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "catalist_* имеет фиксированное число итераций для обоих метаалгоритмов.\n",
    "catalist_eps имеет проверку на норму градиента.\n",
    "\n",
    "\n",
    "Видно, что каталист в данном случае сходится плохо из-за того, что на каждой итерации из-за шага во внешнем цикле (по x) его отбрасывает в большие значений функции.\n",
    "В экспериментах 0 и 2 из-за малого числа итераций в алгоритме, решающем седловую задачу, ведущему к плохой точности решения, каталист расходится.\n",
    "\n",
    "Из-за плохой сходимости catalist_eps не успевает за отведенное число итераций достигнуть точки, в которой произойдет остановка.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
