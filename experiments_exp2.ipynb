{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M = 100, 100 # размерность экспериментов\n",
    "\n",
    "exps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введение.\n",
    "\n",
    "Седловая задача имеет вид $F(x) = \\min_x \\left( f(x) + \\max_y \\left( G(x, y) - h(y) \\right) \\right)$\n",
    "\n",
    "$g(x) = \\max_y \\left( G(x, y) - h(y) \\right)$\n",
    "\n",
    "\n",
    "В данном случае f и g --- это функции вида $\\log(\\sum_{i = 1}^{p} \\exp(\\langle A_i, x \\rangle)) + \\frac{l (\\sum_{i = 1}^{n} x_i^2)}{2}$ (т.е. softmax + регуляризация), где $A$ --- матрица $p \\times n$ с коэффициентом разреженности $0.01$. Все ненулевые элементы выбраны из равномерного распределения $U(-1, 1)$. (как в пункте 3.5 из статьи). $l$ в данном примере равно $1$.\n",
    "\n",
    "$G(x,y) = \\langle x, A(y) x\\rangle$.\n",
    "\n",
    "$A(y)$ представляет собой сумму вида $\\sum_{i = 1}^{k} M_i \\cdot (\\sum_{j = 1}^{m} b_{ij} |y_j|)$.\n",
    "$M_i$ -- матрицы $n \\times n$ положительно определенные.\n",
    "Размер $k = 5$ (при 10 возникают переполнения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp0 = experiment.generateExpQExperiment(\n",
    "    N, M, {'p': 2000, 'sparsity': 0.01}, 1, 1, {'k': 5, 'eigen_min': 1, 'eigen_max': 2}, 10)\n",
    "\n",
    "exps.append(exp0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение седловой задачи**\n",
    "\n",
    "Во внутренней задаче (поиск $y$ для нахождения градиента $g(x)$) для начального значения используется $y$ с предыдущей задачи. Она также решается при помощи ускоренного метаалгоритма.\n",
    "\n",
    "В качестве внутреннего алгоритма используется покомпонентный метод Нестерова.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddle(x_0, y_0, exp, k_out=50, k_in=50, k_n=5, x_grad_stop_eps=None, y_grad_stop_eps=None):\n",
    "    c = exp.constants()\n",
    "    \n",
    "    stop_callback_for_y = None\n",
    "    if y_grad_stop_eps is not None:\n",
    "        stop_callback_for_y = lambda grad: np.sum(grad**2) < y_grad_stop_eps**2\n",
    "        \n",
    "    stop_callback_for_x = None\n",
    "    if x_grad_stop_eps is not None:\n",
    "        stop_callback_for_x = lambda grad: np.sum(grad**2) < x_grad_stop_eps**2\n",
    "    \n",
    "    x, y, stats = experiment.runSaddleExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'out': {\n",
    "            'H': 20,\n",
    "            'K': k_out,\n",
    "            'stop_callback': stop_callback_for_x\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(20)] * N),\n",
    "            'S': np.array([(20 + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': 20,\n",
    "            'K': k_in,\n",
    "            'stop_callback': stop_callback_for_y\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([10] * M),\n",
    "            'S': np.array([(10 + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение седловой задачи с увеличивающейся точностью решения по $y$.**\n",
    "\n",
    "out --- алгоритм по $x$, in --- алгоритм по $y$.\n",
    "\n",
    "Идея заключается в том, что на первых итерациях не тратить много шагов на нахождение точного $y$ (решение внутренней задачи),\n",
    "но при этом постепенно увеличивать точность, чтобы в конце решать задачу для $y$ достаточно точно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddleAdaptiveEps(x_0, y_0, exp, k_out=50, k_in=50, k_n=5, eps_start=10**-4, eps_alpha=0.9998):\n",
    "    c = exp.constants()\n",
    "\n",
    "    class CallbackForY:\n",
    "        def __init__(self, eps_start_, eps_alpha_):\n",
    "            self.eps = eps_start_\n",
    "            self.alpha = eps_alpha\n",
    "            \n",
    "        def __call__(self, grad):\n",
    "            self.eps *= self.alpha\n",
    "            return np.sum(grad**2) < self.eps**2\n",
    "    \n",
    "    x, y, stats = experiment.runSaddleExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'out': {\n",
    "            'H': 20,\n",
    "            'K': k_out,\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(20)] * N),\n",
    "            'S': np.array([(20 + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': 20,\n",
    "            'K': k_in,\n",
    "            'stop_callback': CallbackForY(eps_start, eps_alpha)\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([10] * M),\n",
    "            'S': np.array([(10 + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Каталист**\n",
    "\n",
    "Обычное решение дополнительно обернуто в еще один УМ с $f = 0$ и $g = F$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSaddleCatalist(x_0, y_0, exp, k_catalist, H, k_out=50, k_in=50, k_n=5, x_grad_stop_eps=None, y_grad_stop_eps=None):\n",
    "    c = exp.constants()\n",
    "    \n",
    "    stop_callback_for_y = None\n",
    "    if y_grad_stop_eps is not None:\n",
    "        stop_callback_for_y = lambda grad: np.sum(grad**2) < y_grad_stop_eps**2\n",
    "        \n",
    "    stop_callback_for_x = None\n",
    "    if x_grad_stop_eps is not None:\n",
    "        stop_callback_for_x = lambda grad: np.sum(grad**2) < x_grad_stop_eps**2\n",
    "\n",
    "    x, y, stats = experiment.runSaddleCatalistExperiment(exp, {\n",
    "        'x_0': x_0,\n",
    "        'y_0': y_0,\n",
    "        'catalist': {\n",
    "            'H': H,\n",
    "            'K': k_catalist,\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'out': {\n",
    "            'H': 20,\n",
    "            'K': k_out,\n",
    "            'stop_callback': stop_callback_for_x\n",
    "        },\n",
    "        'out_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([(20)] * N),\n",
    "            'S': np.array([(20 + 1)**(1/2)] * N),\n",
    "            'stop_callback': None\n",
    "        },\n",
    "        'in': {\n",
    "            'H': 20,\n",
    "            'K': k_in,\n",
    "            'stop_callback': stop_callback_for_y\n",
    "        },\n",
    "        'in_nesterov': {\n",
    "            'K': k_n,\n",
    "            'Li': np.array([10] * M),\n",
    "            'S': np.array([(10 + 1)**(1/2)] * M),\n",
    "            'stop_callback': None\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return x, y, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_res = lambda exp, x, y: exp.f.func(x) + exp.G.func(x, y) - exp.h.func(y)\n",
    "calc_grad_x = lambda exp, x, y: np.sqrt(np.sum((exp.f.grad(x) + exp.G.grad_x(x, y))**2))\n",
    "calc_grad_y = lambda exp, x, y: np.sqrt(np.sum((exp.G.grad_y(x, y) - exp.h.grad(y))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.678338374476013, 35.21003314343351)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "x_0 = np.random.random(N)\n",
    "y_0 = np.random.random(M)\n",
    "\n",
    "np.sum(x_0**2),np.sum(y_0**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эксперимент 0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0367c1250b51>\u001b[0m in \u001b[0;36mRunSaddle\u001b[0;34m(x_0, y_0, exp, k_out, k_in, k_n, x_grad_stop_eps, y_grad_stop_eps)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m'Li'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;34m'S'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;34m'stop_callback'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         }\n\u001b[1;32m     37\u001b[0m     })\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/experiment.py\u001b[0m in \u001b[0;36mrunSaddleExperiment\u001b[0;34m(experiment, settings, seed)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out_nesterov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         settings['in'], settings['in_nesterov'])\n\u001b[0m\u001b[1;32m    291\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36mSolveSaddle\u001b[0;34m(x_0, y_0, f, G, h, out_settings, out_nesterov_settings, in_settings, in_nesterov_settings)\u001b[0m\n\u001b[1;32m    237\u001b[0m             x_00, oracle, out_nesterov_settings),\n\u001b[1;32m    238\u001b[0m         \u001b[0mout_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_callback'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         lambda f__, g__, x: f.func(x) + G.func(x, g.y_last) - h.func(g.y_last))\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_last\u001b[0m  \u001b[0;31m# copy.deepcopy(g).optimal_y(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36mAcceleratedMetaalgorithmSolver\u001b[0;34m(x_0, f, g, H, K, subproblemCallback, stopCallback, fCallback)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mf_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mg_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_new\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mf_grad\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_new\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimal_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_stoh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36moptimal_y\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubproblemCallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopCallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             lambda h__, G_y__, y: self.f.func(x) + self.G.func(x, y) - self.h.func(y))\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malg_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36mAcceleratedMetaalgorithmSolver\u001b[0;34m(x_0, f, g, H, K, subproblemCallback, stopCallback, fCallback)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         y_new, in_iters = subproblemCallback(\n\u001b[0;32m---> 88\u001b[0;31m             x_, SubproblemOracle(OmegaOracle(f, x_), g, x_, H))\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mf_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(y_00, oracle)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         lambda y_00, oracle: NesterovAcceleratedSolver(\n\u001b[0;32m--> 231\u001b[0;31m             y_00, oracle, in_nesterov_settings),\n\u001b[0m\u001b[1;32m    232\u001b[0m         in_settings['stop_callback'])\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/Disk3/hse/3course/vo/optimization_project/optimization.py\u001b[0m in \u001b[0;36mNesterovAcceleratedSolver\u001b[0;34m(x_0, oracle, settings)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# from https://github.com/dmivilensky/accelerated-taylor-descent/blob/master/ms%20taylor%20contract.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mS_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;31m# from https://github.com/dmivilensky/accelerated-taylor-descent/blob/master/ms%20taylor%20contract.ipynb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mS_sm\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6bd6c0a7f929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x, y, stat = RunSaddle(x_0, y_0, exp, 100, 40, 5)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Simple (100, 40): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_grad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_grad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_grad_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_grad_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mres_simple_40\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "res_simple_50 = []\n",
    "res_simple_40 = []\n",
    "res_simple_20 = []\n",
    "res_simple_eps = []\n",
    "res_simple_adaptive = []\n",
    "\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    #%time x, y, stat = RunSaddle(x_0, y_0, exp, 80, 50, 5)\n",
    "    #print('Simple (100, 40): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    #res_simple_50.append(stat)\n",
    "    \n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 100, 40, 5)\n",
    "    print('Simple (100, 40): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_40.append(stat)\n",
    "    \n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 200, 20, 5)\n",
    "    print('Simple (200, 20): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_20.append(stat)\n",
    "\n",
    "    %time x, y, stat = RunSaddle(x_0, y_0, exp, 200, 20, 5, None, 1e-3)\n",
    "    print('Simple EPS=1e-3 (200, 20): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_simple_eps.append(stat)\n",
    "    \n",
    "    #%time x, y, stat = RunSaddleAdaptiveEps(x_0, y_0, exp, 200, 30, 5, 1e-1, 0.9998)\n",
    "    #print('Adaptive EPS=1e-2 alpha=0.9997 (200, 20): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    #res_simple_adaptive.append(stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_catalist_20 = []\n",
    "res_catalist_40 = []\n",
    "\n",
    "for i, exp in enumerate(exps):\n",
    "    print('Эксперимент {}.'.format(i))\n",
    "\n",
    "    %time x, y, stat = RunSaddleCatalist(x_0, y_0, exp, 20, 15, 20, 20, 5)\n",
    "    print('Catalist (20, 20, 10): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    res_catalist_20.append(stat)\n",
    "    \n",
    "    #%time x, y, stat = RunSaddleCatalist(x_0, y_0, exp, 40, 15, 10, 20, 5)\n",
    "    #print('Catalist (40, 10, 10): f(x, y)={}\\n||f\\'_x(x_0, y_0)||={} ||f\\'_x(x, y)||={}\\n||f\\'_y(x_0, y_0)||={} ||f\\'_y(x, y)||={}'.format(calc_res(exp, x, y), calc_grad_x(exp, x_0, y_0), calc_grad_x(exp, x, y), calc_grad_y(exp, x_0, y_0), calc_grad_y(exp, x, y)))\n",
    "    #res_catalist_40.append(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectFfromfOracleSimple(stats):\n",
    "    return stats['out_stats']['fs']\n",
    "\n",
    "def collectFfromhOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r += st['fs']\n",
    "    return r\n",
    "\n",
    "def collectGradNormfromfOracleSimple(stats):\n",
    "    return stats['out_stats']['gs']\n",
    "\n",
    "def collectGradNormfromhOracleSimple(stats):\n",
    "    r = []\n",
    "    for st in stats['in_stats']:\n",
    "        r += st['gs']\n",
    "    return r\n",
    "\n",
    "def collectFfromfOracleCatalist(stats):\n",
    "    r = []\n",
    "    for st in stats['saddle']:\n",
    "        r += collectFfromfOracleSimple(st)\n",
    "    return r\n",
    "\n",
    "def collectFfromhOracleCatalist(stats):\n",
    "    r = []\n",
    "    for st in stats['saddle']:\n",
    "        r += collectFfromhOracleSimple(st)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(2, 1, 1 + i * 2)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    #Ff = collectFfromfOracleSimple(res_simple_50[i])\n",
    "    #ax.plot(range(len(Ff)), Ff, label='simple_50')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_40')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_20[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_20')\n",
    "    \n",
    "    Ff = collectFfromfOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='simple_eps')\n",
    "    \n",
    "    #Ff = collectFfromfOracleSimple(res_simple_adaptive[i])\n",
    "    #ax.plot(range(len(Ff)), Ff, label='simple_adaptive')\n",
    "        \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 1, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    #Fh = collectFfromhOracleSimple(res_simple_50[i])\n",
    "    #ax.plot(range(len(Fh)), Fh, label='simple_50')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_40')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_20[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_20')\n",
    "    \n",
    "    Fh = collectFfromhOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='simple_eps')\n",
    "    \n",
    "    #Fh = collectFfromhOracleSimple(res_simple_adaptive[i])\n",
    "    #ax.plot(range(len(Fh)), Fh, label='simple_adaptive')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(2, 1, 1 + i * 2 + 0)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    #Gf = collectGradNormfromfOracleSimple(res_simple_50[i])\n",
    "    #ax.plot(range(len(Gf)), Gf, label='simple_50')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_40')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_20[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_20')\n",
    "    \n",
    "    Gf = collectGradNormfromfOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Gf)), Gf, label='simple_eps')\n",
    "    \n",
    "    #Gf = collectGradNormfromfOracleSimple(res_simple_adaptive[i])\n",
    "    #ax.plot(range(len(Gf)), Gf, label='simple_adaptive')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('$||\\\\nabla F_x||$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 1, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "\n",
    "    #Gh = collectGradNormfromhOracleSimple(res_simple_50[i])\n",
    "    #ax.plot(range(len(Gh)), Gh, label='simple_50')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_40[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_40')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_20[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_20')\n",
    "    \n",
    "    Gh = collectGradNormfromhOracleSimple(res_simple_eps[i])\n",
    "    ax.plot(range(len(Gh)), Gh, label='simple_eps')\n",
    "    \n",
    "    #Gh = collectGradNormfromhOracleSimple(res_simple_adaptive[i])\n",
    "    #ax.plot(range(len(Gh)), Gh, label='simple_adaptive')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('$||\\\\nabla F_y||$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "simple_* имеют фиксированное число итераций для обоих метаалгоритмов, число означает кол-во итераций поиска по $y$ для одной итерации поиска по $x$.\n",
    "simple_eps имеет проверку на норму градиента для остановки.\n",
    "\n",
    "\n",
    "Здесь результат такой же, как и в квадратичных экспериментах, т.е. быстрее сходится метод, которые делает больше итераций внешнего алгоритма, поскольку в данном случае в f и h одинаковые.\n",
    "\n",
    "При этом видно, что точность решения задачи по $x$ для методов simple_20 и simple_eps одинакова, хотя simple_eps решает дополнительную задачу с меньшей точностью и делает там меньше шагов.\n",
    "\n",
    "\n",
    "На графиках по $\\nabla h$ есть вертикальные линии (на самом деле они не вертикальные, а так кажется из-за того, что они занимают мало итераций, при том, что на графике итераций десятки тысяч), которые возникают из-за того, что после сдвига по $x$ надо перерешивать задачу по $y$, поскольку он теперь не максимизирует функцию. Чем больше сдвиг по $x$ влияет на функцию, тем больше эти линии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(len(exps)):\n",
    "    ax = plt.subplot(2, 1, 1 + i * 2)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    Ff = collectFfromfOracleCatalist(res_catalist_40[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='catalist_40')\n",
    "\n",
    "    Ff = collectFfromfOracleCatalist(res_catalist_20[i])\n",
    "    ax.plot(range(len(Ff)), Ff, label='catalist_20')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla f$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    ax = plt.subplot(2, 1, 1 + i * 2 + 1)\n",
    "    ax.set_title('Эксперимент {}.'.format(i))\n",
    "    \n",
    "    #Fh = collectFfromhOracleCatalist(res_catalist_40[i])\n",
    "    #ax.plot(range(len(Fh)), Fh, label='catalist_40')\n",
    "    \n",
    "    Fh = collectFfromhOracleCatalist(res_catalist_20[i])\n",
    "    ax.plot(range(len(Fh)), Fh, label='catalist_20')\n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('значение $F(x, y)$')\n",
    "    plt.xlabel('вызов оракула $\\\\nabla h$')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Вывод**\n",
    "\n",
    "\n",
    "catalist_* имеет фиксированное число итераций для обоих метаалгоритмов, число означает кол-во итераций итерации внешнего цикла алгоритма Каталист.\n",
    "\n",
    "Здесь также, как и в случае квадратичных форм, каталист сходится хуже, чем простой метод, а, если решать седловую задачу недостаточно точно (catalist_40), то даже расхоидтся."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
